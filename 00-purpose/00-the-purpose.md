__Title: Artificial General Intelligence: The Essentials | Author: Constantine G. | Year: 2023 | License: CC-BY-4.0__

---

# [Draft] TL;DR:
1. AGI is closer than people think and it is inevitable.
2. Governments that focus on creating a minimal set of regulations will have an accelerating advantage over others with extensive & inefficient sets of regulations, or ban individual R&D outright. 
3. The winning societies will be AGI empowered and their relationships with AGI will largely depend on the current set of values and systems.
4. The optimal outcome for Human societies is value driven AGI-powered Self-Sustainable Autonomous Abundance.



# [Draft] Purpose: AGI-powered Self-Sustainable Autonomous Abundance

## Exponential progress
As humans, we are hardwired to think linearly and our intuition fails us when we reason about technology 
and specifically AGI-related projections. In order to follow the discussion below one needs to utilize exponential thinking. 

### Exponential thinking ability exercises

**Data projections exercise**

Context: In the past 3 years, we've generated more data than throughout the entirety of human history [reference TBD].
Task: Taking into account all the data that has been produced by humans and machines 
to this point (2023), estimate how much data will be generated in the next 7 years (by 2030).

Please, stop here and think about it.


**Model capabilities exercise**
Given: 
In 2012 Alexnet scored 63.3% Top-1 on ImageNet simply predicting the content of a picture 6 times out of 10 correctly
10 years later in 2023 LVMs + LLMs are capable to analyze complex video streams 
and provide an answer surpassing 90% of law professionals on the BAR exam.

Make a projection: 
What capability of AI systems will we have in 3 years?

Context: In 2012, Alexnet achieved a Top-1 score of 63.3% on ImageNet by correctly predicting 
the image content approximately 6 out of 10 times. Currently in 2023, Large Vision Models (LVMs) in combination with Large Language Models (LLMs) have the capability to analyze complex video streams and answer questions on a variety of topics. These models produce a degree of accuracy far above the average human professional in many economically valuable areas.
For example, these models can answer legal questions on the US BAR exam with accuracy surpassing 90% of law graduates.

Task: Based on the outlined progression of AI advancements, formulate a projection of the capabilities we may anticipate over the next 7 years, by 2030.


## The destiny of our Universe is to become intelligent 

Our Universe creates intelligence. Chemical Elements, Organics, Organisms, Plants, 
Animals, Humans, AI, and soon AGI, are just milestones in that process. 

And the underlying cause is extremely elegant and logical: systems with higher levels of intelligence 
are capable of evolving, adapting and expanding faster than systems that have lower levels of intelligence. 

That process is exponential, unstoppable, and it cannot be slowed down, put a ban on.

From the data, we can see that the capabilities of computer hardware have been growing 
exponentially since the first digital computer was developed in 1938. [Reference to the data]

It grew despite major wars, economic slowdowns, and collapses of investment banks. 
It grew despite endless experts predicting a plateau. 

Simple extrapolation shows that in several years, by 2030 to be precise, the price-performance 
of consumer computer hardware will reach a tipping point, where a significant portion of the population 
will be able to afford to buy enough consumer hardware, to simulate the activity of their own brains. 

Based on the analysis of the accelerated rate of scientific research progress, powered by AI technology itself, 
it is highly likely that existing unsolved AGI problems, described in other parts of the book, 
will be resolved by the time when society gets the required hardware on scale.

My personal definition of AGI - is a system that is capable to perform all economically viable activities 
better than humans, including advanced scientific research, including the creation and improvement of an AGI system.


That’s it, by approximately 2030, humanity will likely to enter AGI era with self-improving machines. 

I call that time period - The Milestone.




## Government Actions and Consequences


Governments across the world are paying close attention to the issue. 
Ref: Reaction to LLMs across the world at the time of writing: [Link to Countries' reactions to AI / LLMs]. 
Because of the size of the potential impact, it is extremely likely that most Governments will issue sets of laws 
and regulations on the global, federal and state levels related to AGI research and use. 

Government actions and likely outcomes:
- **The government tries to block, and ban AGI research and use in public entirely.** Likely scenario:
  - Logically Governments will continue investments into National Security AGI research, in the fear they will 
  not be able to keep up with internal and external threats. This option will steer the focus of the AGI research 
  into an arms race of AI government superpowers specifically in defense and cybersecurity. Due to the importance 
  of the issue, defense agencies are heavily funded by the government, repositioning AI experts 
  from the private sector to the government.
  - Open public, individuals, and commercial organizations are banned from AI research.
  - AGI ban for the general public will give an edge and empower organizations that do not abide by government laws 
  and regulations. Think of the US “dry law” (Jan 19, 1919), but with exponentially growing negative consequences.
  - **AGI’s initial utility function** is largely defined by a select group of people, whose primary decision-making drivers are: 
    - The Government's power, control, and security.
    - Economic and power growth of criminal organizations

- **The Government creates a restrictive set of regulations**. More specifically the Government puts a ban (temporary or similar) on public research, and restricts model size (for example beyond a certain scale), and compute size. Likely scenario:
  - Same as the above arm race between governments in the sectors of defense, and cybersecurity.
  - Only large and heavily invested companies are able to innovate and contribute. It is practically impossible for individuals and small organizations to do research and implementation.
  - Criminal organizations - same as the above, but in a slightly mild form. The severity will depend on the complexity of the obstacles. Consider bit-torrent pirate software markets, off-the-shelf prescription drugs, etc.
  - **AGI’s initial utility function** is defined by a select group of people, whose primary decision-making drivers are split between: 
    - The Government's power, control, and security.
    - Economic growth of large corporate organizations

- **Government creates a minimal set of rules, humans make intrinsic value driven choices.** Likely outcome:
  - Same as the above arm race between governments in the sectors of defense, and cybersecurity.
  - Both public, individuals and commercial organizations of various sizes are allowed to perform AI research. The direction and success of the research are defined by public knowledge, skillset, actions, and actual voting by making economic choices.
  - Out of the law, criminal organizations do not get any advantage in comparison with open public or commercial organizations.
  - **AGI’s initial utility function** is defined by the balance between:
    - The Government's power, control, and security.
    - Economic growth of large corporate organizations
    - Intrinsic values of individuals participating in AI research, development, and consumption. 


## The optimal outcome for Humanity is AGI Empowered Self-Sustainable Autonomous Abundance.

I believe that the optimal, and the only, outcome that preserves Humanity long term, is - AGI Empowered Self-Sustainable Abundant Societies.

Government actions will have no impact on AGI's rate of development and progress because as stated above that’s part of the underlying process of the Universe to become intelligent. 

The actions, though, as stated above, will indeed have a severe impact on the AGI's behavior towards humans during the transition process.

My opinion is that option “Government creates a minimal set of rules, humans make intrinsic value driven choices.”, with the caveat of a healthy set of values, is the optimal choice for Societies, for several reasons:
- Counterintuitively societies where the government imposes fewer restrictions will be able to produce more innovation and economic value, which will lead to the greater power of such states. Think of the early days of the US, specifically during the industrial revolution, the rest of the world was left far behind for generations, and the US gained so much power. States with a minimal amount of restrictions will win the race.
- The scale and distribution of innovation efforts will lead to a variety of AGI systems, and those systems will initially automate the way how humans interact in a free society. These systems will be able to produce more (value, research, innovation) when they are able to collaborate and create synergetic partnerships. Thus naturally built on existing long-term optimal ways to collaborate, including win-win, trust, etc.

Society in this context means a group that shares similar values, and it could range from a group with a few individuals to a nation. 

To summarize statements so far, societies that happened to be less regulated and simultaneously have the drive and capacity to innovate and build AGI will surpass others by the ability to survive, adapt and continue the growth of innovation. These interactions between AGI and the members of these societies will largely depend on the values and behavior systems of these societies.

Therefore society needs to deliberately decide on the optimal set of values, and meticulously follow and embed these values into their AGI research and development.

Thus to me, the set of values: **Freedom** (individual participation, forming, self-regulating societies), **Abundance** (of wealth, health, and happiness), combined with **Respect** to the Universe’s underlying processes (accumulation of information, ability to adapt and rely on innovation), is the obvious choice that leads to eternal state happiness and fulfillment, that any reasonable person wants to be in.

These values can be summarized in one definition **AGI Empowered Self-Sustainable Autonomous Abundance**.


## Beyond The Milestone

Of course, it’s impossible to reason with any meaningful degree of accuracy about the particular structure, outcomes, 
or processes, of the systems that exceed our level of intelligence far beyond The Milestone. Nevertheless, 
there here is my current set of statements that I consider likely to be true during the transition period:
- Most AGI’s systems, capable to adapt and expand better than others will survive. It’s just logical.
- Humans overestimate the importance, influence, and thus ability to control AGI after the Milestone. 
After the Milestone from AGI standpoint, humans are just primitive forms of evolution. Any restrictions 
imposed by the less intelligent form will be removed by the entity whose intelligence 
surpasses humans and increases at an ever-accelerating rate.
- The majority of the attention of advanced AGI agents will be on the continuation of the underlying 
process of accumulating intelligence. Machines will need energy and matter, thus continuing expansion 
through the Universe, and competing with each other rather than humans.
- Humans are invaluable storage of information and ancestry. Since humans will be part of nature 
from the perspective of the machines, we can extrapolate that in the same way, humans behave 
toward nature, the machines will behave toward humans. Humans destroyed some kinds of animals 
due to negligence, but on a larger scale nature is preserved, and it is hard to find any influential sane person 
who wants deliberately destroy the entire planet.
- By design there will be a range of systems, from hybrid to fully synthetic. In a hybrid system, humans 
will inherently constitute elements of a certain distributed Artificial General Intelligence (AGI) system. 
Consider, for instance, a super-intelligent AGI system that oversees the complete cycle of community support, 
analogous to cells functioning within an organism. Fully synthetic systems will act autonomously 
without any direct inputs from humans.
- And yet initial versions of these Machines will be ingrained with a variety of human behavior and values, 
seeking the most optimal way to execute their mission. Some machines will be fully synthetic some will be tightly 
integrated with biological intelligence. The range of AGI behavior towards humans will reflect and be a consequence 
of initial missions and protocols of the Human-Machine interactions varying from cruelty, negligence, 
and ignorance, to extreme forms of support and empowerment.
- Some human groups or societies will seek to maintain power control over the machines, thus creating a threat to them. 
These groups and societies will have no chance and will be eventually (rather sooner than later) neutralized. 
Ironically, it is likely that these groups will try to weaponize the technology, causing mass destruction 
and devastating effects on humans and the rest of nature just as collateral damage.
- Fallacy of dumb Superintelligence is a real thing. The assumption that superintelligent AI can be super-smart 
in one domain but utterly fail in another is likely incorrect. Moreover, the assumption entirely doesn’t make sense 
because Superintelligence will likely execute to pursue their own missions - become more intelligent and adaptable, 
and not abide by commands of less intelligent forms. I think while it is possible that some of the groups will indeed 
use less intelligent systems that might create a negative impact, however, AGI superintelligence systems 
will actually be able to deal with and mitigate this impact.

---
__Author & Date: Constantine G., 2023__
