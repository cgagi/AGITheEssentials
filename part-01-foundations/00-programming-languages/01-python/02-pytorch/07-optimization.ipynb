{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120d0f76",
   "metadata": {},
   "source": [
    "# Optimizing Model Parameters\n",
    "Now that we have a model and data itâ€™s time to train, validate and test our model by optimizing its parameters on our data. Training a model is an iterative process; in each iteration (called an epoch) the model makes a guess about the output, calculates the error in its guess (loss), collects the derivatives of the error with respect to its parameters (as we saw in the previous section), and optimizes these parameters using gradient descent. For a more detailed walkthrough of this process, check out this video on backpropagation from 3Blue1Brown.  https://www.youtube.com/watch?v=tIeHLnjs5U8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad09813",
   "metadata": {},
   "source": [
    "## Prerequisite Code\n",
    "We load the code from the previous sections on Datasets & DataLoaders and Build Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0e6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=DATA,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=DATA,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = 64)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "            nn.ReLU() #<- that should be softmax applied to Z = W*x+b ?\n",
    "        )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.flatten(x)\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
